namespace=embedding.huggingface

# Path to tokenizer.json
tokenizerPath model

# Path to model.onnx
transformerModel  model

# Max length of token sequence model can handle
transformerMaxTokens int default=512

# Input names
transformerInputIds      string default=input_ids
transformerAttentionMask string default=attention_mask
transformerTokenTypeIds  string default=token_type_ids

# Output name
transformerOutput string default=last_hidden_state


# Normalize tensors from tokenizer
normalize bool default=false

poolingStrategy enum { cls, mean } default=mean

# Settings for ONNX model evaluation
transformerExecutionMode enum { parallel, sequential } default=sequential
transformerInterOpThreads int default=1
transformerIntraOpThreads int default=-4
# GPU device id, -1 for CPU
transformerGpuDevice      int default=0
