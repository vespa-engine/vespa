<?xml version="1.0" encoding="utf-8" ?>
<!-- Copyright Vespa.ai. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root. -->
<services version="1.0">

  <container version="1.0">
    <component id="hf-embedder" type="hugging-face-embedder">
      <transformer-model model-id="e5-base-v2" url="https://my/url/model.onnx"/>
      <tokenizer-model model-id="e5-base-v2-vocab" path="app/tokenizer.json"/>
      <max-tokens>1024</max-tokens>
      <transformer-input-ids>my_input_ids</transformer-input-ids>
      <transformer-attention-mask>my_attention_mask</transformer-attention-mask>
      <transformer-token-type-ids>my_token_type_ids</transformer-token-type-ids>
      <transformer-output>my_output</transformer-output>
      <normalize>true</normalize>
      <prepend>
        <query>Represent this sentence for searching relevant passages:</query>
        <document>passage:</document>
      </prepend>
      <onnx-execution-mode>parallel</onnx-execution-mode>
      <onnx-intraop-threads>10</onnx-intraop-threads>
      <onnx-interop-threads>8</onnx-interop-threads>
      <onnx-gpu-device>1</onnx-gpu-device>
      <pooling-strategy>mean</pooling-strategy>
    </component>

    <component id="splade" type="splade-embedder">
      <transformer-model model-id="e5-base-v2" url="https://my/url/model.onnx"/>
      <tokenizer-model model-id="e5-base-v2-vocab" path="app/tokenizer.json"/>
      <max-tokens>1024</max-tokens>
      <transformer-input-ids>my_input_ids</transformer-input-ids>
      <transformer-attention-mask>my_attention_mask</transformer-attention-mask>
      <transformer-token-type-ids>my_token_type_ids</transformer-token-type-ids>
      <transformer-output>my_output</transformer-output>
      <term-score-threshold>0.2</term-score-threshold>
      <onnx-execution-mode>parallel</onnx-execution-mode>
      <onnx-intraop-threads>10</onnx-intraop-threads>
      <onnx-interop-threads>8</onnx-interop-threads>
      <onnx-gpu-device>1</onnx-gpu-device>
    </component>

    <component id="hf-tokenizer" type="hugging-face-tokenizer">
      <model language="no" model-id="multilingual-e5-base-vocab" url="https://my/url/tokenizer.json"/>
    </component>

    <component id="bert-embedder" type="bert-embedder">
      <!-- model specifics -->
      <transformer-model model-id="minilm-l6-v2" url="https://my/url/model.onnx"/>
      <tokenizer-vocab path="files/vocab.txt"/>
      <max-tokens>512</max-tokens>
      <transformer-input-ids>my_input_ids</transformer-input-ids>
      <transformer-attention-mask>my_attention_mask</transformer-attention-mask>
      <transformer-token-type-ids/>
      <transformer-output>my_output</transformer-output>
      <transformer-start-sequence-token>101</transformer-start-sequence-token>
      <transformer-end-sequence-token>102</transformer-end-sequence-token>


      <!-- tunable parameters: number of threads etc -->
      <onnx-execution-mode>parallel</onnx-execution-mode>
      <onnx-intraop-threads>4</onnx-intraop-threads>
      <onnx-interop-threads>8</onnx-interop-threads>
      <onnx-gpu-device>1</onnx-gpu-device>
    </component>

    <component id="colbert" type="colbert-embedder">
      <transformer-model model-id="e5-base-v2" url="https://my/url/model.onnx"/>
      <tokenizer-model model-id="e5-base-v2-vocab" path="app/tokenizer.json"/>
      <max-tokens>1024</max-tokens>
      <max-query-tokens>32</max-query-tokens>
      <max-document-tokens>512</max-document-tokens>
      <transformer-start-sequence-token>101</transformer-start-sequence-token>
      <transformer-end-sequence-token>102</transformer-end-sequence-token>
      <transformer-mask-token>103</transformer-mask-token>
      <transformer-pad-token>0</transformer-pad-token>
      <transformer-input-ids>my_input_ids</transformer-input-ids>
      <transformer-attention-mask>my_attention_mask</transformer-attention-mask>
      <transformer-output>my_output</transformer-output>
      <onnx-execution-mode>parallel</onnx-execution-mode>
      <onnx-intraop-threads>10</onnx-intraop-threads>
      <onnx-interop-threads>8</onnx-interop-threads>
      <onnx-gpu-device>1</onnx-gpu-device>
    </component>

    <nodes>
      <node hostalias="node1" />
    </nodes>
  </container>

</services>
